{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-20T20:04:51.714373300Z",
     "start_time": "2023-07-20T20:04:51.649989500Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dense.__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4136\\2504908197.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;31m# Adım 4 - YSA\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m \u001B[0mclassifier\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDense\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_dim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m128\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'relu'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[0mclassifier\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDense\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_dim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'sigmoid'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\keras\\dtensor\\utils.py\u001B[0m in \u001B[0;36m_wrap_function\u001B[1;34m(layer_instance, *args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m                     \u001B[0mlayout_args\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mvariable_name\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"_layout\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 96\u001B[1;33m         \u001B[0minit_method\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayer_instance\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     97\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m         \u001B[1;31m# Inject the layout parameter after the invocation of __init__()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Dense.__init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# ilkleme\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adım 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Adım 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# 2. convolution katmanı\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adım 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adım 4 - YSA\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n",
    "# CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# CNN ve resimler\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('veriler/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 1,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('veriler/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 1,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 1,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "test_set.reset()\n",
    "pred=classifier.predict_generator(test_set,verbose=1)\n",
    "#pred = list(map(round,pred))\n",
    "pred[pred > .5] = 1\n",
    "pred[pred <= .5] = 0\n",
    "\n",
    "print('prediction gecti')\n",
    "#labels = (training_set.class_indices)\n",
    "\n",
    "test_labels = []\n",
    "\n",
    "for i in range(0,int(203)):\n",
    "    test_labels.extend(np.array(test_set[i][1]))\n",
    "\n",
    "print('test_labels')\n",
    "print(test_labels)\n",
    "\n",
    "#labels = (training_set.class_indices)\n",
    "'''\n",
    "idx = []\n",
    "for i in test_set:\n",
    "    ixx = (test_set.batch_index - 1) * test_set.batch_size\n",
    "    ixx = test_set.filenames[ixx : ixx + test_set.batch_size]\n",
    "    idx.append(ixx)\n",
    "    print(i)\n",
    "    print(idx)\n",
    "'''\n",
    "dosyaisimleri = test_set.filenames\n",
    "#abc = test_set.\n",
    "#print(idx)\n",
    "#test_labels = test_set.\n",
    "sonuc = pd.DataFrame()\n",
    "sonuc['dosyaisimleri']= dosyaisimleri\n",
    "sonuc['tahminler'] = pred\n",
    "sonuc['test'] = test_labels\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm = confusion_matrix(test_labels, pred)\n",
    "print (cm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2662 images belonging to 2 classes.\n",
      "Found 203 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\furka\\AppData\\Local\\Temp\\ipykernel_4136\\1382302170.py:46: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2659/8000 [========>.....................] - ETA: 30s - loss: 0.5407 - accuracy: 0.7134WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.5406 - accuracy: 0.7137 - val_loss: 0.3193 - val_accuracy: 0.7488\n",
      "  1/203 [..............................] - ETA: 28s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\furka\\AppData\\Local\\Temp\\ipykernel_4136\\1382302170.py:54: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred = classifier.predict_generator(test_set, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 6ms/step\n",
      "[[151   0]\n",
      " [ 52   0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Initialize the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2nd convolution layer\n",
    "classifier.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Fully Connected Layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the CNN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data Generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('veriler/training_set',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=1,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('veriler/test_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=1,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "# Train the CNN\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000,\n",
    "                         epochs=1,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=2000)\n",
    "\n",
    "# Make Predictions\n",
    "test_set.reset()\n",
    "pred = classifier.predict_generator(test_set, verbose=1)\n",
    "pred[pred > 0.5] = 1\n",
    "pred[pred <= 0.5] = 0\n",
    "\n",
    "# Get true labels from the test set\n",
    "test_labels = []\n",
    "for i in range(0, int(203)):\n",
    "    test_labels.extend(np.array(test_set[i][1]))\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "dosyaisimleri = test_set.filenames\n",
    "sonuc = pd.DataFrame()\n",
    "sonuc['dosyaisimleri'] = dosyaisimleri\n",
    "sonuc['tahminler'] = pred.flatten()\n",
    "sonuc['test'] = test_labels\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, pred)\n",
    "print(cm)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T20:05:13.027038200Z",
     "start_time": "2023-07-20T20:04:53.408270Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
