{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T09:20:20.041823300Z",
     "start_time": "2023-09-16T09:20:19.651991700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     windspeed  winddirection  PitchAngle  temperature  \\\ntimestamp                                                                \n2019-01-01 00:00:00        5.2     147.600006        -1.8          5.0   \n2019-01-01 00:10:00        5.4     138.600006        -2.1          5.0   \n2019-01-01 00:20:00        5.0     141.500000        -1.7          5.0   \n2019-01-01 00:30:00        3.5     132.000000         0.6          5.0   \n2019-01-01 00:40:00        3.8     136.899994         0.0          5.0   \n\n                     WindSpeedCube       power     x_com     y_com  Hour  \\\ntimestamp                                                                  \n2019-01-01 00:00:00        140.608  180.899994 -4.390506  2.786299   0.0   \n2019-01-01 00:10:00        157.464  213.300003 -4.050600  3.571084   0.0   \n2019-01-01 00:20:00        125.000  164.100006 -3.913041  3.112573   0.0   \n2019-01-01 00:30:00         42.875   21.799999 -2.341957  2.601007   0.0   \n2019-01-01 00:40:00         54.872   48.299999 -2.774616  2.596441   0.0   \n\n                     DayOfWeek  Month  WindSpeedRollingMean  PowerRollingMean  \\\ntimestamp                                                                       \n2019-01-01 00:00:00        1.0    1.0                   0.0               0.0   \n2019-01-01 00:10:00        1.0    1.0                   0.0               0.0   \n2019-01-01 00:20:00        1.0    1.0                   0.0               0.0   \n2019-01-01 00:30:00        1.0    1.0                   0.0               0.0   \n2019-01-01 00:40:00        1.0    1.0                   0.0               0.0   \n\n                     DayOfWeekSin  DayOfWeekCos  HourSin  HourCos  MonthSin  \\\ntimestamp                                                                     \n2019-01-01 00:00:00      0.781831       0.62349      0.0      1.0       0.0   \n2019-01-01 00:10:00      0.781831       0.62349      0.0      1.0       0.0   \n2019-01-01 00:20:00      0.781831       0.62349      0.0      1.0       0.0   \n2019-01-01 00:30:00      0.781831       0.62349      0.0      1.0       0.0   \n2019-01-01 00:40:00      0.781831       0.62349      0.0      1.0       0.0   \n\n                     MonthCos  \ntimestamp                      \n2019-01-01 00:00:00       1.0  \n2019-01-01 00:10:00       1.0  \n2019-01-01 00:20:00       1.0  \n2019-01-01 00:30:00       1.0  \n2019-01-01 00:40:00       1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>windspeed</th>\n      <th>winddirection</th>\n      <th>PitchAngle</th>\n      <th>temperature</th>\n      <th>WindSpeedCube</th>\n      <th>power</th>\n      <th>x_com</th>\n      <th>y_com</th>\n      <th>Hour</th>\n      <th>DayOfWeek</th>\n      <th>Month</th>\n      <th>WindSpeedRollingMean</th>\n      <th>PowerRollingMean</th>\n      <th>DayOfWeekSin</th>\n      <th>DayOfWeekCos</th>\n      <th>HourSin</th>\n      <th>HourCos</th>\n      <th>MonthSin</th>\n      <th>MonthCos</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01 00:00:00</th>\n      <td>5.2</td>\n      <td>147.600006</td>\n      <td>-1.8</td>\n      <td>5.0</td>\n      <td>140.608</td>\n      <td>180.899994</td>\n      <td>-4.390506</td>\n      <td>2.786299</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 00:10:00</th>\n      <td>5.4</td>\n      <td>138.600006</td>\n      <td>-2.1</td>\n      <td>5.0</td>\n      <td>157.464</td>\n      <td>213.300003</td>\n      <td>-4.050600</td>\n      <td>3.571084</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 00:20:00</th>\n      <td>5.0</td>\n      <td>141.500000</td>\n      <td>-1.7</td>\n      <td>5.0</td>\n      <td>125.000</td>\n      <td>164.100006</td>\n      <td>-3.913041</td>\n      <td>3.112573</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 00:30:00</th>\n      <td>3.5</td>\n      <td>132.000000</td>\n      <td>0.6</td>\n      <td>5.0</td>\n      <td>42.875</td>\n      <td>21.799999</td>\n      <td>-2.341957</td>\n      <td>2.601007</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 00:40:00</th>\n      <td>3.8</td>\n      <td>136.899994</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>54.872</td>\n      <td>48.299999</td>\n      <td>-2.774616</td>\n      <td>2.596441</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten, Input, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    " # Loading the wind dataset\n",
    "df = pd.read_csv(\"C:/users/FurkanBulut/Desktop/T1totalclean.csv\", index_col=\"timestamp\", parse_dates=True)\n",
    "df.head()\n",
    "#Calculate Wind Speed cube for each row and create a new column named \"WindSpeedCube\"\n",
    "df['WindSpeedCube'] = df['windspeed']**3\n",
    "\n",
    "#Make last column to power \n",
    "df = df[[\"windspeed\",\"winddirection\",\"PitchAngle\",\"temperature\",\"WindSpeedCube\",\"power\"]]\n",
    "\n",
    "df.head()\n",
    "#Nan value yerine mean degeri koy\n",
    "df = df.fillna(df.mean())   \n",
    "\n",
    "#Power can not be negative, so make all negative values to zero\n",
    "df.loc[df['power'] < 0, 'power'] = 0\n",
    "\n",
    "df.describe\n",
    "\n",
    "#Function to create x,y components of wind speed\n",
    "#function to create x,y component of wind direction \n",
    "def x_y_component(wind_direction, wind_speed):\n",
    "    \"\"\"Convert degrees to x,y components\"\"\"\n",
    "#convert to radians     \n",
    "    radians = (wind_direction * np.pi)/180\n",
    "# give the x, y compenents     \n",
    "    x = wind_speed * np.cos(radians)\n",
    "    y = wind_speed * np.sin(radians)\n",
    "    return x,y\n",
    "# create two extra columns in raw_data_nm for x,y compnenents of wind direction df['x_com'], df['y_com'] = x_y_component(df['WindDirection'],                                                           df['WindSpeed'])\n",
    "df.head()\n",
    "\n",
    "# create two extra columns in raw_data_nm for x,y compnenents of wind direction \n",
    "df['x_com'], df['y_com'] = x_y_component(df['winddirection'],df['windspeed'])\n",
    "df.head()\n",
    "df[\"Hour\"] = df.index.hour\n",
    "df[\"DayOfWeek\"] = df.index.dayofweek\n",
    "df[\"Month\"] = df.index.month\n",
    "df.head ()\n",
    "# Create rolling mean and standard deviation features for wind speed, temperature, and power\n",
    "df['WindSpeedRollingMean'] = df['windspeed'].rolling(window=24).mean()\n",
    "df['PowerRollingMean'] = df['power'].rolling(window=24).mean()\n",
    "\n",
    "df.head()\n",
    "\n",
    "#Nan değerleri sıfır yap\n",
    "df = df.fillna(0)\n",
    "df.isnull().sum()\n",
    "\n",
    "#df nin bütün verilerini nümerik hale getir\n",
    "df = df.apply(pd.to_numeric)\n",
    "df.head()\n",
    "#Hout, DayOfWeek, Month kolonlarını float yap\n",
    "df['Hour'] = df['Hour'].astype(float)\n",
    "df['DayOfWeek'] = df['DayOfWeek'].astype(float)\n",
    "df['Month'] = df['Month'].astype(float)\n",
    "df.dtypes\n",
    "#Day of week, hour, month kolonlarının sinüs ve kosinüs değerlerini al\n",
    "df['DayOfWeekSin'] = np.sin(df.DayOfWeek*(2.*np.pi/7))\n",
    "df['DayOfWeekCos'] = np.cos(df.DayOfWeek*(2.*np.pi/7))\n",
    "df['HourSin'] = np.sin(df.Hour*(2.*np.pi/24))\n",
    "df['HourCos'] = np.cos(df.Hour*(2.*np.pi/24))\n",
    "df['MonthSin'] = np.sin((df.Month-1)*(2.*np.pi/12))\n",
    "df['MonthCos'] = np.cos((df.Month-1)*(2.*np.pi/12))\n",
    "df.head()\n",
    "def create_lag(df: pd.core.frame.DataFrame, column: str, lags: list) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that allows to create lagged features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.core.frame.DataFrame\n",
    "        Data which contains feature.\n",
    "    \n",
    "    column : str\n",
    "        column to be transformed.\n",
    "    \n",
    "    lags : list\n",
    "        Lag numbers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.core.frame.DataFrame\n",
    "        Lagged feature.\n",
    "\n",
    "    \"\"\"\n",
    "    for lag in lags:\n",
    "        df[column + \"_lag_\" + str(lag)] = df[column].shift(periods=lag).astype(np.float32)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = create_lag(df=df, column=\"windspeed\", lags=[1, 2, 3, 6])\n",
    "df = create_lag(df=df, column=\"winddirection\", lags=[1, 2, 3, 6])\n",
    "df = create_lag(df=df, column=\"PitchAngle\", lags=[1, 2, 3, 6])\n",
    "df = create_lag(df=df, column=\"power\", lags=[1, 2, 3, 6])\n",
    "df = create_lag(df=df, column=\"x_com\", lags=[1, 2, 3, 6])\n",
    "df = create_lag(df=df, column=\"y_com\", lags=[1, 2, 3, 6])\n",
    "df = create_lag(df=df, column=\"temperature\", lags=[1, 2, 3, 6])\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>windspeed</th>\n",
       "      <th>winddirection</th>\n",
       "      <th>PitchAngle</th>\n",
       "      <th>temperature</th>\n",
       "      <th>WindSpeedCube</th>\n",
       "      <th>power</th>\n",
       "      <th>x_com</th>\n",
       "      <th>y_com</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>...</th>\n",
       "      <th>power_lag_3</th>\n",
       "      <th>power_lag_6</th>\n",
       "      <th>x_com_lag_1</th>\n",
       "      <th>x_com_lag_2</th>\n",
       "      <th>x_com_lag_3</th>\n",
       "      <th>x_com_lag_6</th>\n",
       "      <th>y_com_lag_1</th>\n",
       "      <th>y_com_lag_2</th>\n",
       "      <th>y_com_lag_3</th>\n",
       "      <th>y_com_lag_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>5.2</td>\n",
       "      <td>147.600006</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>140.608</td>\n",
       "      <td>180.899994</td>\n",
       "      <td>-4.390506</td>\n",
       "      <td>2.786299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:10:00</th>\n",
       "      <td>5.4</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>157.464</td>\n",
       "      <td>213.300003</td>\n",
       "      <td>-4.050600</td>\n",
       "      <td>3.571084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.390625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.787109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:20:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>141.500000</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>125.000</td>\n",
       "      <td>164.100006</td>\n",
       "      <td>-3.913041</td>\n",
       "      <td>3.112573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.050781</td>\n",
       "      <td>-4.390625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.570312</td>\n",
       "      <td>2.787109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:30:00</th>\n",
       "      <td>3.5</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.875</td>\n",
       "      <td>21.799999</td>\n",
       "      <td>-2.341957</td>\n",
       "      <td>2.601007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>180.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.912109</td>\n",
       "      <td>-4.050781</td>\n",
       "      <td>-4.390625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.113281</td>\n",
       "      <td>3.570312</td>\n",
       "      <td>2.787109</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:40:00</th>\n",
       "      <td>3.8</td>\n",
       "      <td>136.899994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.872</td>\n",
       "      <td>48.299999</td>\n",
       "      <td>-2.774616</td>\n",
       "      <td>2.596441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>213.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.341797</td>\n",
       "      <td>-3.912109</td>\n",
       "      <td>-4.050781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.601562</td>\n",
       "      <td>3.113281</td>\n",
       "      <td>3.570312</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     windspeed  winddirection  PitchAngle  temperature  \\\n",
       "timestamp                                                                \n",
       "2019-01-01 00:00:00        5.2     147.600006        -1.8          5.0   \n",
       "2019-01-01 00:10:00        5.4     138.600006        -2.1          5.0   \n",
       "2019-01-01 00:20:00        5.0     141.500000        -1.7          5.0   \n",
       "2019-01-01 00:30:00        3.5     132.000000         0.6          5.0   \n",
       "2019-01-01 00:40:00        3.8     136.899994         0.0          5.0   \n",
       "\n",
       "                     WindSpeedCube       power     x_com     y_com  Hour  \\\n",
       "timestamp                                                                  \n",
       "2019-01-01 00:00:00        140.608  180.899994 -4.390506  2.786299   0.0   \n",
       "2019-01-01 00:10:00        157.464  213.300003 -4.050600  3.571084   0.0   \n",
       "2019-01-01 00:20:00        125.000  164.100006 -3.913041  3.112573   0.0   \n",
       "2019-01-01 00:30:00         42.875   21.799999 -2.341957  2.601007   0.0   \n",
       "2019-01-01 00:40:00         54.872   48.299999 -2.774616  2.596441   0.0   \n",
       "\n",
       "                     DayOfWeek  ...  power_lag_3  power_lag_6  x_com_lag_1  \\\n",
       "timestamp                       ...                                          \n",
       "2019-01-01 00:00:00        1.0  ...          NaN          NaN          NaN   \n",
       "2019-01-01 00:10:00        1.0  ...          NaN          NaN    -4.390625   \n",
       "2019-01-01 00:20:00        1.0  ...          NaN          NaN    -4.050781   \n",
       "2019-01-01 00:30:00        1.0  ...      180.875          NaN    -3.912109   \n",
       "2019-01-01 00:40:00        1.0  ...      213.250          NaN    -2.341797   \n",
       "\n",
       "                     x_com_lag_2  x_com_lag_3  x_com_lag_6  y_com_lag_1  \\\n",
       "timestamp                                                                 \n",
       "2019-01-01 00:00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 00:10:00          NaN          NaN          NaN     2.787109   \n",
       "2019-01-01 00:20:00    -4.390625          NaN          NaN     3.570312   \n",
       "2019-01-01 00:30:00    -4.050781    -4.390625          NaN     3.113281   \n",
       "2019-01-01 00:40:00    -3.912109    -4.050781          NaN     2.601562   \n",
       "\n",
       "                     y_com_lag_2  y_com_lag_3  y_com_lag_6  \n",
       "timestamp                                                   \n",
       "2019-01-01 00:00:00          NaN          NaN          NaN  \n",
       "2019-01-01 00:10:00          NaN          NaN          NaN  \n",
       "2019-01-01 00:20:00     2.787109          NaN          NaN  \n",
       "2019-01-01 00:30:00     3.570312     2.787109          NaN  \n",
       "2019-01-01 00:40:00     3.113281     3.570312          NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['temperature_lag_1', 'temperature_lag_2','temperature_lag_3', 'temperature_lag_6','PitchAngle_lag_2', 'PitchAngle_lag_3','PitchAngle_lag_6','winddirection_lag_1','winddirection_lag_2','winddirection_lag_6'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "windspeed               0\n",
       "winddirection           0\n",
       "PitchAngle              0\n",
       "temperature             0\n",
       "WindSpeedCube           0\n",
       "power                   0\n",
       "x_com                   0\n",
       "y_com                   0\n",
       "Hour                    0\n",
       "DayOfWeek               0\n",
       "Month                   0\n",
       "WindSpeedRollingMean    0\n",
       "PowerRollingMean        0\n",
       "DayOfWeekSin            0\n",
       "DayOfWeekCos            0\n",
       "HourSin                 0\n",
       "HourCos                 0\n",
       "MonthSin                0\n",
       "MonthCos                0\n",
       "windspeed_lag_1         0\n",
       "windspeed_lag_2         0\n",
       "windspeed_lag_3         0\n",
       "windspeed_lag_6         0\n",
       "winddirection_lag_3     0\n",
       "PitchAngle_lag_1        0\n",
       "power_lag_1             0\n",
       "power_lag_2             0\n",
       "power_lag_3             0\n",
       "power_lag_6             0\n",
       "x_com_lag_1             0\n",
       "x_com_lag_2             0\n",
       "x_com_lag_3             0\n",
       "x_com_lag_6             0\n",
       "y_com_lag_1             0\n",
       "y_com_lag_2             0\n",
       "y_com_lag_3             0\n",
       "y_com_lag_6             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill nan values with 0\n",
    "df = df.fillna(0)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivar_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "def clean_data(series):\n",
    "    \"\"\"Fills missing values. \n",
    "    \n",
    "        Interpolate missing values with a linear approximation.\n",
    "    \"\"\"\n",
    "    series_filled = series.interpolate(method='linear')\n",
    "        \n",
    "    return series_filled\n",
    "        \n",
    "    \n",
    "def min_max_scale(dataframe):\n",
    "    \"\"\" Applies MinMax Scaling\n",
    "    \n",
    "        Wrapper for sklearn's MinMaxScaler class.\n",
    "    \"\"\"\n",
    "    mm = MinMaxScaler()\n",
    "    return mm.fit_transform(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivarate Datasets\n",
      "Train Data Shape: (110644, 37)\n",
      "Val Data Shape: (47419, 37)\n",
      "Test Data Shape: (19282, 37)\n",
      "Nulls In Train False\n",
      "Nulls In Validation False\n",
      "Nulls In Test False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def split_data(series, train_fraq, test_len=25000):\n",
    "    \"\"\"Splits input series into train, val and test.\n",
    "    \n",
    "        Default to 1 year of test data.\n",
    "    \"\"\"\n",
    "    #slice the last %10 of data for testing has point \n",
    "    test_slice = len(series)-test_len\n",
    "\n",
    "    test_data = series[test_slice:]\n",
    "    train_val_data = series[:test_slice]\n",
    "\n",
    "    #make train and validation from the remaining\n",
    "    train_size = int(len(train_val_data) * train_fraq)\n",
    "    \n",
    "    train_data = train_val_data[:train_size]\n",
    "    val_data = train_val_data[train_size:]\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "multivar_df = clean_data(multivar_df)\n",
    "\n",
    "#scale\n",
    "multivar_df = min_max_scale(multivar_df)\n",
    "train_multi, val_multi, test_multi = split_data(multivar_df, train_fraq=0.7, test_len=19282)\n",
    "print(\"Multivarate Datasets\")\n",
    "print(f\"Train Data Shape: {train_multi.shape}\")\n",
    "print(f\"Val Data Shape: {val_multi.shape}\")\n",
    "print(f\"Test Data Shape: {test_multi.shape}\")\n",
    "print(f\"Nulls In Train {np.any(np.isnan(train_multi))}\")\n",
    "print(f\"Nulls In Validation {np.any(np.isnan(val_multi))}\")\n",
    "print(f\"Nulls In Test {np.any(np.isnan(test_multi))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sample shapes\n",
      "x =  (1, 720, 37)\n",
      "y =  (1, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "def window_dataset(data, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=False, expand_dims=False):\n",
    "    \"\"\" Create a windowed tensorflow dataset\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #create a window with n steps back plus the size of the prediction length\n",
    "    window = n_steps + n_horizon\n",
    "    \n",
    "    #expand dimensions to 3D to fit with LSTM inputs\n",
    "    #creat the inital tensor dataset\n",
    "    if expand_dims:\n",
    "        ds = tf.expand_dims(data, axis=-1)\n",
    "        ds = tf.data.Dataset.from_tensor_slices(ds)\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(data)\n",
    "    \n",
    "    #create the window function shifting the data by the prediction length\n",
    "    ds = ds.window(window, shift=n_horizon, drop_remainder=True)\n",
    "    \n",
    "    #flatten the dataset and batch into the window size\n",
    "    ds = ds.flat_map(lambda x : x.batch(window))\n",
    "    ds = ds.shuffle(shuffle_buffer)    \n",
    "    \n",
    "    #create the supervised learning problem x and y and batch\n",
    "    if multi_var:\n",
    "        ds = ds.map(lambda x : (x[:-n_horizon], x[-n_horizon:, :1]))\n",
    "    else:\n",
    "        ds = ds.map(lambda x : (x[:-n_horizon], x[-n_horizon:]))\n",
    "    \n",
    "    ds = ds.batch(batch_size).prefetch(1)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "n_steps = 720\n",
    "n_horizon = 6\n",
    "batch_size = 1\n",
    "shuffle_buffer = 100\n",
    "\n",
    "\n",
    "ds = window_dataset(train_multi, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=True)\n",
    "\n",
    "print('Example sample shapes')\n",
    "for idx,(x,y) in enumerate(ds):\n",
    "    print(\"x = \", x.numpy().shape)\n",
    "    print(\"y = \", y.numpy().shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction lookback (n_steps): 720\n",
      "Prediction horizon (n_horizon): 6\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 37), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(train_fraq=0.7, \n",
    "                  n_steps=24*6*5, \n",
    "                  n_horizon=6, \n",
    "                  batch_size=256, \n",
    "                  shuffle_buffer=500, \n",
    "                  expand_dims=False, \n",
    "                  multi_var=False):\n",
    "    \"\"\"If multi variate then first column is always the column from which the target is contstructed.\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.random.set_seed(23)\n",
    "    \n",
    "    if multi_var:\n",
    "        data = multivar_df\n",
    "    \n",
    "    else:\n",
    "        data = multivar_df['power']\n",
    "        \n",
    "\n",
    "    \n",
    "    if multi_var:\n",
    "        mm = MinMaxScaler()\n",
    "        data = mm.fit_transform(data)\n",
    "    \n",
    "    train_data, val_data, test_data = split_data(data, train_fraq=train_fraq, test_len=8760)\n",
    "    \n",
    "    train_ds = window_dataset(train_data, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=multi_var, expand_dims=expand_dims)\n",
    "    val_ds = window_dataset(val_data, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=multi_var, expand_dims=expand_dims)\n",
    "    test_ds = window_dataset(test_data, n_steps, n_horizon, batch_size, shuffle_buffer, multi_var=multi_var, expand_dims=expand_dims)\n",
    "    \n",
    "    \n",
    "    print(f\"Prediction lookback (n_steps): {n_steps}\")\n",
    "    print(f\"Prediction horizon (n_horizon): {n_horizon}\")\n",
    "    print(f\"Batch Size: {batch_size}\")\n",
    "    print(\"Datasets:\")\n",
    "    print(train_ds.element_spec)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "train_ds, val_ds, test_ds = build_dataset(multi_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(multivar=False):\n",
    "    lr = 3e-4\n",
    "    n_steps=24*6*5\n",
    "    n_horizon=6\n",
    "    \n",
    "    if multivar:\n",
    "        n_features=37\n",
    "    else:\n",
    "        n_features=1\n",
    "        \n",
    "    return n_steps, n_horizon, n_features, lr\n",
    "\n",
    "model_configs = dict()\n",
    "\n",
    "def cfg_model_run(model, history, test_ds):\n",
    "    return {\"model\": model, \"history\" : history, \"test_ds\": test_ds}\n",
    "\n",
    "\n",
    "def run_model(model_name, model_func, model_configs, epochs):\n",
    "    \n",
    "    n_steps, n_horizon, n_features, lr = get_params(multivar=True)\n",
    "    train_ds, val_ds, test_ds = build_dataset(n_steps=n_steps, n_horizon=n_horizon, multi_var=True)\n",
    "\n",
    "    model = model_func(n_steps, n_horizon, n_features, lr=lr)\n",
    "\n",
    "    model_hist = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "\n",
    "    model_configs[model_name] = cfg_model_run(model, model_hist, test_ds)\n",
    "    return test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 26640)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3410048   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,427,334\n",
      "Trainable params: 3,427,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def dnn_model(n_steps, n_horizon, n_features, lr):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(n_steps, n_features)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(n_horizon)\n",
    "    ], name='dnn')\n",
    "    \n",
    "    loss=tf.keras.losses.Huber()\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "    \n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['mae', \"mse\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "dnn = dnn_model(*get_params(multivar=True))\n",
    "dnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(dnn, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 715, 64)           14272     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 357, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 355, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 177, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 11328)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11328)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1450112   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,477,510\n",
      "Trainable params: 1,477,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cnn_model(n_steps, n_horizon, n_features, lr=3e-4):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv1D(64, kernel_size=6, activation='relu', input_shape=(n_steps,n_features)),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(n_horizon)\n",
    "    ], name=\"CNN\")\n",
    "    \n",
    "    loss= tf.keras.losses.Huber()\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['mae', \"mse\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "cnn = cnn_model(*get_params(multivar=True))\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(cnn, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 720, 72)           31680     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,958\n",
      "Trainable params: 61,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def lstm_model(n_steps, n_horizon, n_features, lr):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(72, activation='relu', input_shape=(n_steps, n_features), return_sequences=True),\n",
    "        tf.keras.layers.LSTM(48, activation='relu', return_sequences=False),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(n_horizon)\n",
    "    ], name='lstm')\n",
    "    \n",
    "    loss = tf.keras.losses.Huber()\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "    \n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['mae', \"mse\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm = lstm_model(*get_params(multivar=True))\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(lstm, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 715, 64)           14272     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 357, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 355, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 177, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 177, 72)           39456     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,358\n",
      "Trainable params: 96,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def lstm_cnn_model(n_steps, n_horizon, n_features, lr):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv1D(64, kernel_size=6, activation='relu', input_shape=(n_steps,n_features)),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.LSTM(72, activation='relu', return_sequences=True),\n",
    "        tf.keras.layers.LSTM(48, activation='relu', return_sequences=False),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(n_horizon)\n",
    "    ], name=\"lstm_cnn\")\n",
    "    \n",
    "    loss = tf.keras.losses.Huber()\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "    \n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['mae', \"mse\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm_cnn = lstm_cnn_model(*get_params(multivar=True))\n",
    "lstm_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(lstm_cnn, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_skip\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main (InputLayer)              [(None, 720, 37)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 715, 64)      14272       ['main[0][0]']                   \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 357, 64)      0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 355, 64)      12352       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 177, 64)     0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 177, 72)      39456       ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 48)           23232       ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 48)           0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 26640)        0           ['main[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 26688)        0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 26688)        0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          3416192     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6)            774         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,506,278\n",
      "Trainable params: 3,506,278\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def lstm_cnn_skip_model(n_steps, n_horizon, n_features, lr):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "   \n",
    "    inputs = tf.keras.layers.Input(shape=(n_steps,n_features), name='main')\n",
    "    \n",
    "    conv1 = tf.keras.layers.Conv1D(64, kernel_size=6, activation='relu')(inputs)\n",
    "    max_pool_1 = tf.keras.layers.MaxPooling1D(2)(conv1)\n",
    "    conv2 = tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu')(max_pool_1)\n",
    "    max_pool_2 = tf.keras.layers.MaxPooling1D(2)(conv2)\n",
    "    lstm_1 = tf.keras.layers.LSTM(72, activation='relu', return_sequences=True)(max_pool_2)\n",
    "    lstm_2 = tf.keras.layers.LSTM(48, activation='relu', return_sequences=False)(lstm_1)\n",
    "    flatten = tf.keras.layers.Flatten()(lstm_2)\n",
    "    \n",
    "    skip_flatten = tf.keras.layers.Flatten()(inputs)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate(axis=-1)([flatten, skip_flatten])\n",
    "    drop_1 = tf.keras.layers.Dropout(0.3)(concat)\n",
    "    dense_1 = tf.keras.layers.Dense(128, activation='relu')(drop_1)\n",
    "    drop_2 = tf.keras.layers.Dropout(0.3)(dense_1)\n",
    "    output = tf.keras.layers.Dense(n_horizon)(drop_2)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name='lstm_skip')\n",
    "    \n",
    "    loss = tf.keras.losses.Huber()\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "    \n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['mae', \"mse\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm_skip = lstm_cnn_skip_model(*get_params(multivar=True))\n",
    "lstm_skip.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(lstm_skip, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction lookback (n_steps): 720\n",
      "Prediction horizon (n_horizon): 6\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 37), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\FURKAN~1\\AppData\\Local\\Temp\\__autograph_generated_file1owkquuv.py\", line 12, in tf__train_function\n        retval_ = ag__.UndefinedReturnValue()\n\n    AttributeError: module 'tensorflow.python.autograph.operators' has no attribute 'UndefinedReturnValue'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-23-017bf2748d42>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mmodel_configs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mrun_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"dnn\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdnn_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_configs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mrun_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"cnn\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcnn_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_configs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mrun_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"lstm\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlstm_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_configs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mrun_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"lstm_cnn\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlstm_cnn_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_configs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-11-067f0e7dafdd>\u001B[0m in \u001B[0;36mrun_model\u001B[1;34m(model_name, model_func, model_configs, epochs)\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_steps\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_horizon\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m     \u001B[0mmodel_hist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_ds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval_ds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[0mmodel_configs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcfg_model_run\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_hist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_ds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mtf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     10\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFunctionScope\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'train_function'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'fscope'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mConversionOptions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecursive\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0muser_requested\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptional_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minternal_convert_user_code\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mfscope\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m                 \u001B[0mdo_return\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m                 \u001B[0mretval_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mUndefinedReturnValue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m                     \u001B[0mdo_return\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: in user code:\n\n    File \"C:\\Users\\FURKAN~1\\AppData\\Local\\Temp\\__autograph_generated_file1owkquuv.py\", line 12, in tf__train_function\n        retval_ = ag__.UndefinedReturnValue()\n\n    AttributeError: module 'tensorflow.python.autograph.operators' has no attribute 'UndefinedReturnValue'\n"
     ]
    }
   ],
   "source": [
    "model_configs=dict()\n",
    "run_model(\"dnn\", dnn_model, model_configs, epochs=1)\n",
    "run_model(\"cnn\", cnn_model, model_configs, epochs=1)\n",
    "run_model(\"lstm\", lstm_model, model_configs, epochs=0)\n",
    "run_model(\"lstm_cnn\", lstm_cnn_model, model_configs, epochs=0)\n",
    "run_model(\"lstm_skip\", lstm_cnn_skip_model, model_configs, epochs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dnn model\n",
    "dnn.save(\"C:/Users/FurkanBulut/Desktop/test/T1dnn.h5\")\n",
    "#save cnn model\n",
    "cnn.save(\"C:/Users/FurkanBulut/Desktop/test/T1cnn.h5\")\n",
    "#save lstm model\n",
    "lstm.save(\"C:/Users/FurkanBulut/Desktop/test/T1lstm.h5\")\n",
    "#save lstm_cnn model\n",
    "lstm_cnn.save(\"C:/Users/FurkanBulut/Desktop/test/T1lstm_cnn.h5\")\n",
    "#save lstm_skip model\n",
    "lstm_skip.save(\"C:/Users/FurkanBulut/Desktop/test/T1lstm_skip.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = list()\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25,5))\n",
    "\n",
    "def plot_graphs(metric, val, ax, upper):\n",
    "    ax.plot(val['history'].history[metric])\n",
    "    ax.plot(val['history'].history[f'val_{metric}'])\n",
    "    ax.set_title(key)\n",
    "    ax.legend([metric, f\"val_{metric}\"])\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_ylim([0, upper])\n",
    "    \n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    plot_graphs(\"loss\", val, ax, 0.08)\n",
    "print(\"Loss Curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE Curves\")\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25,5))\n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    plot_graphs('mae', val, ax, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse for each model\n",
    "for key, val in model_configs.items():\n",
    "    print(f\"{key} RMSE: {val['model'].evaluate(val['test_ds'])[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list()\n",
    "performance = list()\n",
    "\n",
    "for key, value in model_configs.items():\n",
    "    names.append(key)\n",
    "    mae = value['model'].evaluate(value['test_ds'])\n",
    "    performance.append(mae[1])\n",
    "    \n",
    "performance_df = pd.DataFrame(performance, index=names, columns=['mae'])\n",
    "performance_df['error_mw'] = performance_df['mae'] * df['power'].mean()\n",
    "print(performance_df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 1, figsize=(30, 20))\n",
    "days = 6\n",
    "\n",
    "vline = np.linspace(0, days,)\n",
    "\n",
    "for (key, val), ax in zip(model_configs.items(), axs):\n",
    "\n",
    "    test = val['test_ds']\n",
    "    preds = val['model'].predict(test)\n",
    "    xbatch, ybatch = iter(test).get_next()\n",
    "    ybatch = ybatch.numpy()[:days]\n",
    "    print(ybatch)\n",
    "    ax.plot(ybatch.reshape(-1))\n",
    "    ax.plot(preds[:days].reshape(-1))\n",
    "    ax.set_title(key)\n",
    "    ax.vlines(vline, ymin=0, ymax=1, linestyle='dotted', transform = ax.get_xaxis_transform())\n",
    "    ax.legend([\"Actual\", \"Predicted\"])\n",
    "\n",
    "plt.xlabel(\"Minutes Cumulative\")\n",
    "print('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw actual and predicted values\n",
    "fig, axs = plt.subplots(5, 1, figsize=(30, 20))\n",
    "days = 7\n",
    "\n",
    "vline = np.linspace(0, days, days+1)\n",
    "\n",
    "for (key, val), ax in zip(model_configs.items(), axs):\n",
    "    \n",
    "        test = val['test_ds']\n",
    "        preds = val['model'].predict(test)\n",
    "    \n",
    "        xbatch, ybatch = iter(test).get_next()\n",
    "    \n",
    "        ax.plot(ybatch.numpy()[:days].reshape(-1))\n",
    "        ax.plot(preds[:days].reshape(-1))\n",
    "        ax.set_title(key)\n",
    "        ax.vlines(vline, ymin=0, ymax=1, linestyle='dotted', transform = ax.get_xaxis_transform())\n",
    "        ax.legend([\"Actual\", \"Predicted\"])\n",
    "\n",
    "plt.xlabel(\"Minutes Cumulative\")\n",
    "print('Predictions')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
